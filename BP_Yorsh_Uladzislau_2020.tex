% arara: xelatex
% arara: xelatex
% arara: xelatex


% options:
% thesis=B bachelor's thesis
% thesis=M master's thesis
% czech thesis in Czech language
% english thesis in English language
% hidelinks remove colour boxes around hyperlinks

\documentclass[thesis=B,english]{FITthesis}[2019/12/23]

%\usepackage[utf8]{inputenc} % LaTeX source encoded as UTF-8
% \usepackage[latin2]{inputenc} % LaTeX source encoded as ISO-8859-2
\usepackage[cp1250]{inputenc} % LaTeX source encoded as Windows-1250

% \usepackage{subfig} %subfigures
% \usepackage{amsmath} %advanced maths
% \usepackage{amssymb} %additional math symbols

\usepackage{dirtree} %directory tree visualisation
\usepackage{amssymb}

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 
% EDIT THIS
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 

\department{Department of Applied Mathematics}
\title{Detecting abnormalities in X-Ray images using Neural Networks}
\authorGN{Uladzislau} %author's given name/names
\authorFN{Yorsh} %author's surname
\author{Uladzislau Yorsh} %author's name without academic degrees
\authorWithDegrees{Uladzislau Yorsh} %author's name with academic degrees
\supervisor{Ing. Jakub {\v Z}itn{\' y}}
\acknowledgements{Give a thank to the supervisor and family}
\abstractEN{Rheumatoid arthritis (RA) is a systemic inflammatory autoimmune disease affecting 0.5 to 1 \% of adult people in the developed world. This disease attacks the synovium, results in swollen and painful joints and, in severe cases, leads to disability. The current approach in diagnosing and quantifying damage is a manual radiographic image inspection by a radiologist, which is generally expensive, time-consuming and subjective. Automated assessment systems are a way to overcome this problems and introduce more objectivity into radiology reports, coupled with a faster damage quantifying.
	
The possibility of such a system development will be shown on the example of a participation in RA2 DREAM Challenge. As a part of the competition, the system utilizing several state-of-art convolutional neural net architectures will be developed and scored on the University of Alabama at Birmingham Cheaha supercomputing system.}
\abstractCS{Revmatoidn{\' i} artritida (RA) je syst{\' e}mov{\' e} z{\' a}n{\v e}tliv{\' e} autoimunitn{\' i} onemocn{\v e}n{\' i}, postihuj{\' i}c{\' i} 0,5 a{\v z} 1 \% dosp{\v e}l{\' y}ch lid{\' i} v rozvinut{\' e}m sv{\v e}t{\v e}. Dan{\' a} nemoc vyvol{\' a}v{\' a} chronick{\' y} z{\' a}n{\v e}t synovi{\' a}ln{\' i} tk{\' a}n{\v e}, co{\v z} vede k nevr{\' a}tn{\' e}mu po{\v s}kozen{\' i} chrup{\' a}vek a kost{\' i} kloub{\r u}. Sou{\v c}asn{\' y} p{\v r}{\' i}stup k diagnostice a hodnocen{\' i} po{\v s}kozen{\' i} je vizu{\' a}ln{\' i} inspekce rentgenov{\' y}ch sn{\' i}mk{\r u} radiologem, kter{\' a} je obecn{\v e} drah{\' a}, {\v c}asov{\v e} n{\' a}ro{\v c}n{\' a} a subjektivn{\' i}. Aumtomatick{\' e} hodnot{\' i}c{\' i} syst{\' e}my jsou jedn{\' i}m ze sp{\r u}sob{\r u} tyto probl{\' e}my p{\v r}ekonat a zav{\' e}st do radiologick{\' y}ch zpr{\' a}v v{\' i}ce objektivity spolu s rychlej{\v s}{\' i}m vy{\v c}{\' i}slen{\' i}m {\v s}kody.

Mo{\v z}nost vytvo{\v r}en{\' i} takov{\' e}ho syst{\' e}mu bude uk{\' a}z{\' a}na na p{\v r}{\' i}kladu {\' u}{\v c}asti v RA2 DREAM Challenge. V r{\' a}mci sout{\v e}{\v z}e na z{\' a}klad{\v e} n{\v e}kolika modern{\' i}ch architektur konvolu{\v c}n{\' i}ch neuronov{\' y}ch s{\' i}t{\' i} bude vyvinut syst{\' e}m, kter{\' y} pozd{\v e}ji bude ohodnocen na vypo{\v c}etn{\' i}m clusteru Birmingham Cheaha na University of Alabama.}
\placeForDeclarationOfAuthenticity{Prague}
\keywordsCS{strojov{\' e} u{\v c}en{\' i}, neuronov{\' e} s{\' i}t{\v e}, automatizovan{\' e} hodnocen{\' i}, medic{\' i}nsk{\' y} software}
\keywordsEN{machine learning, neural networks, automated assessment, medical software}
\declarationOfAuthenticityOption{4} %select as appropriate, according to the desired license (integer 1-6)
% \website{http://site.example/thesis} %optional thesis URL


\begin{document}

% \newacronym{CVUT}{{\v C}VUT}{{\v C}esk{\' e} vysok{\' e} u{\v c}en{\' i} technick{\' e} v Praze}
% \newacronym{FIT}{FIT}{Fakulta informa{\v c}n{\' i}ch technologi{\' i}}

\setsecnumdepth{part}
\chapter{Introduction}


\setsecnumdepth{all}
\chapter{Background}

From the basic concepts of a supervised learning through the overfitting problem and its solutions to the deep learning and convolutional neural networks, this article gives a brief overview of the techniques being used.

More detailed methodology is described in the next chapter. 

\section{Machine Learning}

\textbf{Machine learning (ML)} is the study of computer algorithms that improve automatically through experience\cite{machine_learning}. This interdisciplinary study lies on the border of mathematical statistics, mathematical optimization and classic math disciplines. However, it has its own specifics related to the practical application of such algorithms, like computational efficiency and overfitting.

Machine Learning is often being seen as a subset of artificial intelligence. Indeed, the machine learning \textit{model} is being created by learning on examples instead of an explicit programming. This principle allows to approach problems being impractically or extremely difficult to program manually, such as image recognition, medical diagnosing, financial analysis and many others.

To learn, a \textit{data set} is needed to experience the model on. Data set is a set of individual \textit{samples}, each sample describing one object or one situation. Depending on the data set shape and a task being solved, a machine learning methods may be divided to:
\begin{itemize}
	\item \textbf{Supervised learning}, which is one of the most common ML techniques, standing on the usage of labeled data sets
	\item \textbf{Unsupervised learning}, using unlabeled data and trying to understand their structure itself
	\item \textbf{Reinforcement learning}, where machine learning system interacts with a certain environment and tries to understand its rules
	\item \textbf{More exotic branches}, such as semi-supervised learning, meta-learning and other
\end{itemize}

Description of the whole variety of machine learning approaches is out of scope of this thesis, and the attention will be given to the supervised learning techniques.

\section{Supervised Learning}

Supervised learning stands on using labeled datasets, where an every sample is coupled with a ground truth value:

\[ X = ((x_1, y_1), (x_2, y_2), (x_3, y_3), \dots,(x_n, y_n)) \]
where $x_i$ is a \textit{i\textsuperscript{th}} sample and $y_i$ is a desired model output after taking $x_i$ as an input. The goal of a supervised learning algorithm is to find such parameters of a model $f$  that will approximate the unknown underlying distribution $y_i = \hat{f}(x_i)$\cite{theoretical_ml}, or \textit{fit the training set}.

Supervised learning tasks can be divided further depending on the output values space:
\begin{itemize}
	\item If the set of valid outputs is finite, it's about the \textbf{classification} task ("yes/no" or category assignment)
	\item If the set of valid outputs is ordered and large enough to consider it infinite, or numeric, it's about the \textbf{regression} task (age, price estimation)
\end{itemize}
\textit{Ranking} (ordering an input data) and \textit{forecasting} (prediction of subsequent elements of a certain sequence) tasks also may be distinguished, albeit they heavily intersect with the previous two.

To define how good the model approximates the given data, the \textit{loss function} (or simply \textit{loss}) is being defined based on the difference between the model output and the ground truth. With a proper function choice, the learning task may be defined as a loss function optimization with respect to the model parameters. This allows to employ powerful numeric optimization algorithms.

The key difference between supervised learning and a straightforward numerical optimization is that optimization algorithm do care only about the model output over the training data, regardless the generalization. This may lead to the so-called \textit{overfitting} problem, when the model memorizes data instead of learning a pattern.

\section{Overfitting}

Low loss function value over the training data doesn't guarantee good performance over unseen samples. The plain example is a model memorizing a training data set and having a zero error on it, but yielding random output in response to the unknown input. This example graphically shows the difference between memorizing and generalizing.

Ergo, \textbf{overfitting} may be defined as a case when the model fits the training data well, but performs poorly on unseen data. To detect the overfitting, one needs to test a model over data not included into the training set. Thus, not all data are being fed into the model during training, but some part is being left untouched until it comes to the estimator performance evaluation. This piece of data is often referred as a \textbf{test set}.

Overfitting is a frequent situation when using powerful models, such as artificial neural nets. These models may represent a very large set of different functions including more complex than necessary to describe the distribution from which the training set was drawn. The problem is in dense relation with the Occam's Razor, and an overfitting occured implies violation the principle\cite{overfitting}.

To combat overfitting, variety of methods is being applied:
\begin{itemize}
	\item \textbf{Gathering more data.} More samples \textit{from the same distribution} means that during training the model will see more diverse and densely located data points and will be less prone to memorizing instead of pattern extraction. One should pay attention to the data quality while collecting them: low-quality and noisy data may \textit{decrease} the model performance.
	\item \textbf{Usage of a simpler model.} It's possible to design a model powerful enough to explain data, but too weak to yield an overcomplicated function, since noise's pattern is significantly more complex.
	\item \textbf{Regularization.} Regularization is a process of adding additional constraints to the model. This technique is densely related to the previous point---regularized model's representative power is being limited to fit the data but not the noise.
	
	Model weight norm is usually being penalized; artificial neural nets may be regularized by zeroing output of a random neuron during training (so-called \textit{dropout}). Further regularization techniques also exist.
	\item \textbf{Data augmentation.} Data augmentation is a technique of an artificial samples number increasing without collecting more data. This involves transforming a sample without changing its semantic. A typical example is an image mirroring and rotation: if the task is to classify a cat photo as "Cat", the mirrored or rotated image still will contain the cat on it and may be appended to the training set under the same label.
\end{itemize}

It's worth to mention that \textbf{underfitting} also may occur when the model:
\begin{itemize}
	\item Wasn't trained enough and needs more training iterations to fit the data
	\item \textit{Too weak} to fit the data
\end{itemize}

The second case may be illustrated by fitting the quadratic data with linear regression model. Model weakness usually appears as similar, unsatisfying and not improving performance on both training and test data. The solution is straightforward: more complex model.

\section{Models and Hyperparameter Tuning}

Machine learning \textbf{model} is a parameterized function used to approximate and generalize the underlying data. This function may be represented by a mathematical function (linear regression), set of rules (decision trees) or more complex methematical structure (neural networks). The model itself may represent multiple specific functions depending on its parameters, and the training process is being run to automatically pick them.

But there are values responsible to the \textit{shape} of model, such as a polynom degree in polynomial regression, tree depth in decision trees or an entire neural network architecture. These values cannot be learned since they have to be defined before the model instantiation, and should be picked by a machine learning specialist. These values are called \textbf{hyperparameters} and the process of picking the right hyperparameter value is called \textit{tuning}. Tuning stands on analysing the model performance on unseen data after training.

Hyperparameters cannot be tuned on the same data the model performance is being estimated on. By picking the best hyperparameter after testing it on a certain data set one adapts the model to this specific piece of data, and the model performance on it will be biased towards the better result. Thus, one has to tune hyperparameter on a \textbf{validation} data set disjoint from training and test sets.

Summary:
\begin{itemize}
	\item On the \textbf{training} set the model is being trained
	\item By performance on the \textbf{validation} set the best model is being chosen
	\item The model performance on the \textbf{test} set is an unbiased estimation of it's performance in practice
\end{itemize}

\section{Deep Learning}

\textbf{Deep learning} is a subset of machine learning relying on deep artificial neural networks (ANN) application. Word "deep" refers to the large number of hidden layers of the neural networks being used.

Deep Learning is notably different from the rest of machine learning methods, primarily due to the unique ANN capabilities. The key differences are:
\begin{itemize}
	\item \textbf{No feature engineering required.} Classic ML algorithms heavily rely on the initial process of constructing more representative features from the raw data. This approach is problem-specific and often requires an expertise in a related domain. One of the most important (if not the most one) of the ANN advantages is a capability to infer high-level features by themselves, simplifying the data preparation and letting the ML specialist to approach a problem without a domain-specific expertise.
	
	\item \textbf{DL approach can produce end-to-end solutions.} Classic ML approach requires a problem breakdown to several subtasks which are then being individually approached with different models and manual feature engineering. Deep Learning allows to produce a solid model able to produce output directly after being fed with data. This not only simplifies the model development, but also ensures that the model is being trained as a whole maximizing the interaction between its specialized blocks.
	
	\item \textbf{ANNs often can be transferred to solve similar problem.} An already trained ANN can be used as a baseline for an another task solution. By partial or full re-training this ANN on a new data the better and faster result may be achieved. One of the most common applications of the \textit{transfer leraning} is an image recognition.
	
	\item \textbf{ANNs often require huge amount of data for training...}
	This disadvantage is related primarily to classification/regression ANNs, since the only accompanying information they get with a sample during training is a single value. If the model gets an image with a "Cat" label, it has to infer by itself what is needed to classify this image as "Cat". Since most state-of-art deep learning models got millions of parameters, this requires proportional data amount to not overfit.
	
	\item \textbf{...but sometimes they not.} At the same time, several ANN architectures (semantic segmentation, object detection, \dots) during training recieve a ground truth map instad of a label. This map contains a target value \textit{for an every pixel}. Such amount of related information may be enough to train a model from scratch on tens of images.

	\item \textbf{ANN training requires a lot of computational power.} ANNs are based on numerous matrix multiplications, which are memory-hungry and require specialized hardware such as GPU or TPU for speeding up. This disadvantage limits ANN combination with several time-consuming techniques like cross-validation or ensembling.
	
	\item \textbf{ANNs are hard to interpret.} Another major advantage of non-Deep Learning ML approach and the reason why it still dominates in several sectors. While it's pretty easy to interpret and visualize linear regression models or decision trees, ANN makes its decisions through numerous matrix multiplications which are hard to depict graphically and explain in human terms.
	
	Neural network interpretability is a wide field for research.
\end{itemize} 

\section{Convolutional Neural Networks}



\section{Performance Improvement Techniques}

Refer to Ensembling, Cross-validation, BatchNorm, Dropout, Adam optimizer papers

\chapter{State of the Art}

More detailed methodology description

\section{DenseNet}

DENSENET FANCY PICTURE

ARCHITECTURE DESCTIPTION

COMPARISON WITH RESNET / INCEPTIONV3

\section{Mask R-CNN}

MRCNN FANCY PICTURE

MRCNN ARCHITECTURE DESCRIPTION

\section{Training Improvement Techniques}
TRANSFER LEARNING

SPECIALIZED DROPOUTS FOR DENSENET

Optional - Adam optimizer

\chapter{Analysis and Design}

This chapter describes an approach used to solve the related task step-by-step. The problem will be decomposed to the several subtasks, and for each of them---from the data preprocessing to the joint scoring itself---the solution will be designed using the methodology described in the previous two chapters.

The exact realization will be discussed in the next chapter.

\section{Task Recapitulation}

The goal of the RA2 Challenge is to design a system able to perform a joint damage assessment by the Sharp/van der Heijde (SvH) method. The assessment system stands on examining selected joints of the hands, wrist and feet, which are the typical RA targets. The system considers the joint's \textbf{erosion} (physical damage of the joint's bones) and the joint's \textbf{narrowing} (reduction of the free space between joint's bones). Each erosion and narrowing region is being scored in range from 0 to 5 and from 0 to 4 respectively. The regions involved are shown on the figures; the whole scoring requires 86 examinations yielding the total score in range from 0 to 448.

Note that feet erosion scores are considered per \textit{side} of joint, not the joint itself; the actual feet joint erosion score range is from 0 to 10.

The challenge consists of 3 subchallenges:
\begin{itemize}
	\item \textbf{Subchallenge 1:} Predict overall RA damage. Solution assessment metric: weighted MAE
	\item \textbf{Subchallenge 2:} Predict joint space narrowing jointwise. Solution assessment metric: weighted RMSE
	\item \textbf{Subchallenge 3:} Predict joint erosion jointwise. Solution assessment metric: weighted RMSE
\end{itemize}

It's worth to mention that metrics' weights were not publicly available during the challenge.

The solution must be dockerized, pushed to the challenge repository and submitted through the form; submissions are limited to the 3 per round which is typically a week long. The "Fast lane" unlimited submissions are provided to run the container on a small subset of data and ensure it yields the valid result.

\section{Dataset Analysis}
The data consists of CLEAR and TETRAD studies and contains left hand, right hand, left foot and right foot images of 368 patients, 1472 images in total. The only labels available are 86 SvH scores and their erosion/narrowing/total sums per patient.

The visual inspection revealed that images vary in size, contrast and sharpness. All images are oriented similarly per limb. Among the foreign objects 2 wrist bone plates and several rings were noted.

The label analysis revealed that \textbf{only 14\% of narrowing and 9\% of erosion scores are non-zero}.




INSERT LABEL DISTRIBUTION PLOT THERE




\section{Joint Extraction}

The goal of the related work is to design a model for a joint-by-joint damage assessment. Since every joint is being represented by a relatively small fraction of the image's area, no meaningful result is expected after feeding the current amount of data to the model directly. Thus, to achieve the best result it's needed to extract the joint itself from the original image.

To solve this subtask a pre-trained instance segmentation model was employed.

The next step is to 

DATA SPLIT

DATASET PREPARATION

DETECTOR TRAINING

ESTIMATOR DESIGN

REGULARIZATION



\chapter{Realization Details}

Keras, Colab, VGG Image Annotator, hyperparameters used

\chapter{Experiments}

Tables, graphs, RA2 Challenge results

\setsecnumdepth{part}
\chapter{Conclusion}

Pros and cons, what could be done better, \dots

\bibliographystyle{iso690}
\bibliography{mybibliographyfile}

\setsecnumdepth{all}
\appendix

\chapter{Acronyms}

\begin{description}
	\item[ANN] Artificial Neural Network
	\item[CNN] Convolutional Neural Network
	\item[ML] Machine Learning
	\item[SvH]
	\item[MAE]
	\item[MSE]
\end{description}


\chapter{Contents of enclosed CD}

%change appropriately

\begin{figure}
	\dirtree{%
		.1 readme.txt\DTcomment{the file with CD contents description}.
		.1 exe\DTcomment{the directory with executables}.
		.1 src\DTcomment{the directory of source codes}.
		.2 wbdcm\DTcomment{implementation sources}.
		.2 thesis\DTcomment{the directory of \LaTeX{} source codes of the thesis}.
		.1 text\DTcomment{the thesis text directory}.
		.2 thesis.pdf\DTcomment{the thesis text in PDF format}.
		.2 thesis.ps\DTcomment{the thesis text in PS format}.
	}
\end{figure}

\end{document}
