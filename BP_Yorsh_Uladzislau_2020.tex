% arara: xelatex
% arara: xelatex
% arara: xelatex


% options:
% thesis=B bachelor's thesis
% thesis=M master's thesis
% czech thesis in Czech language
% english thesis in English language
% hidelinks remove colour boxes around hyperlinks

\documentclass[thesis=B,english]{FITthesis}[2019/12/23]

%\usepackage[utf8]{inputenc} % LaTeX source encoded as UTF-8
% \usepackage[latin2]{inputenc} % LaTeX source encoded as ISO-8859-2
\usepackage[cp1250]{inputenc} % LaTeX source encoded as Windows-1250

% \usepackage{subfig} %subfigures
% \usepackage{amsmath} %advanced maths
% \usepackage{amssymb} %additional math symbols

\usepackage{dirtree} %directory tree visualisation
\usepackage{amssymb}

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 
% EDIT THIS
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 

\department{Department of Applied Mathematics}
\title{Detecting abnormalities in X-Ray images using Neural Networks}
\authorGN{Uladzislau} %author's given name/names
\authorFN{Yorsh} %author's surname
\author{Uladzislau Yorsh} %author's name without academic degrees
\authorWithDegrees{Uladzislau Yorsh} %author's name with academic degrees
\supervisor{Ing. Jakub {\v Z}itn{\' y}}
\acknowledgements{Give a thank to the supervisor and family}
\abstractEN{Rheumatoid arthritis (RA) is a systemic inflammatory autoimmune disease affecting 0.5 to 1 \% of adult people in the developed world. This disease attacks the synovium, results in swollen and painful joints and, in severe cases, leads to disability. The current approach in diagnosing and quantifying damage is a manual radiographic image inspection by a radiologist, which is generally expensive, time-consuming and subjective. Automated assessment systems are a way to overcome this problems and introduce more objectivity into radiology reports, coupled with a faster damage quantifying.
	
The possibility of such a system development will be shown on the example of a participation in RA2 DREAM Challenge. As a part of the competition, the system utilizing several state-of-art convolutional neural net architectures will be developed and scored on the University of Alabama at Birmingham Cheaha supercomputing system.}
\abstractCS{Revmatoidn{\' i} artritida (RA) je syst{\' e}mov{\' e} z{\' a}n{\v e}tliv{\' e} autoimunitn{\' i} onemocn{\v e}n{\' i}, postihuj{\' i}c{\' i} 0,5 a{\v z} 1 \% dosp{\v e}l{\' y}ch lid{\' i} v rozvinut{\' e}m sv{\v e}t{\v e}. Dan{\' a} nemoc vyvol{\' a}v{\' a} chronick{\' y} z{\' a}n{\v e}t synovi{\' a}ln{\' i} tk{\' a}n{\v e}, co{\v z} vede k nevr{\' a}tn{\' e}mu po{\v s}kozen{\' i} chrup{\' a}vek a kost{\' i} kloub{\r u}. Sou{\v c}asn{\' y} p{\v r}{\' i}stup k diagnostice a hodnocen{\' i} po{\v s}kozen{\' i} je vizu{\' a}ln{\' i} inspekce rentgenov{\' y}ch sn{\' i}mk{\r u} radiologem, kter{\' a} je obecn{\v e} drah{\' a}, {\v c}asov{\v e} n{\' a}ro{\v c}n{\' a} a subjektivn{\' i}. Aumtomatick{\' e} hodnot{\' i}c{\' i} syst{\' e}my jsou jedn{\' i}m ze sp{\r u}sob{\r u} tyto probl{\' e}my p{\v r}ekonat a zav{\' e}st do radiologick{\' y}ch zpr{\' a}v v{\' i}ce objektivity spolu s rychlej{\v s}{\' i}m vy{\v c}{\' i}slen{\' i}m {\v s}kody.

Mo{\v z}nost vytvo{\v r}en{\' i} takov{\' e}ho syst{\' e}mu bude uk{\' a}z{\' a}na na p{\v r}{\' i}kladu {\' u}{\v c}asti v RA2 DREAM Challenge. V r{\' a}mci sout{\v e}{\v z}e na z{\' a}klad{\v e} n{\v e}kolika modern{\' i}ch architektur konvolu{\v c}n{\' i}ch neuronov{\' y}ch s{\' i}t{\' i} bude vyvinut syst{\' e}m, kter{\' y} pozd{\v e}ji bude ohodnocen na vypo{\v c}etn{\' i}m clusteru Birmingham Cheaha na University of Alabama.}
\placeForDeclarationOfAuthenticity{Prague}
\keywordsCS{strojov{\' e} u{\v c}en{\' i}, neuronov{\' e} s{\' i}t{\v e}, automatizovan{\' e} hodnocen{\' i}, medic{\' i}nsk{\' y} software}
\keywordsEN{machine learning, neural networks, automated assessment, medical software}
\declarationOfAuthenticityOption{4} %select as appropriate, according to the desired license (integer 1-6)
% \website{http://site.example/thesis} %optional thesis URL


\begin{document}

% \newacronym{CVUT}{{\v C}VUT}{{\v C}esk{\' e} vysok{\' e} u{\v c}en{\' i} technick{\' e} v Praze}
% \newacronym{FIT}{FIT}{Fakulta informa{\v c}n{\' i}ch technologi{\' i}}

\setsecnumdepth{part}
\chapter{Introduction}


\setsecnumdepth{all}
\chapter{Background}

From the basic concepts of a supervised learning through the overfitting problem and its solutions to the deep learning and convolutional neural networks, this article gives a brief overview of the techniques being used.

More detailed methodology is described in the next chapter. 

\section{Machine Learning}

\textbf{Machine learning (ML)} is the study of computer algorithms that improve automatically through experience\cite{machine_learning}. This interdisciplinary study lies on the border of mathematical statistics, mathematical optimization and classic math disciplines. However, it has its own specifics related to the practical application of such algorithms, like computational efficiency and overfitting.

Machine Learning is often being seen as a subset of artificial intelligence. Indeed, the machine learning \textit{model} is being created by learning on examples instead of an explicit programming. This principle allows to approach problems being impractically or extremely difficult to program manually, such as image recognition, medical diagnosing, financial analysis and many others.

To learn, a \textit{data set} is needed to experience the model on. Data set is a set of individual \textit{samples}, each sample describing one object or one situation. Depending on the data set shape and a task being solved, a machine learning methods may be divided to:
\begin{itemize}
	\item \textbf{Supervised learning}, which is one of the most common ML techniques, standing on the usage of labeled data sets
	\item \textbf{Unsupervised learning}, using unlabeled data and trying to understand their structure itself
	\item \textbf{Reinforcement learning}, where machine learning system interacts with a certain environment and tries to understand its rules
	\item \textbf{More exotic branches}, such as semi-supervised learning, meta-learning and other
\end{itemize}

Description of the whole variety of machine learning approaches is out of scope of this thesis, and the attention will be given to the supervised learning techniques.

\section{Supervised Learning}

Supervised learning stands on using labeled datasets, where an every sample is coupled with a ground truth value:

\[ X = ((x_1, y_1), (x_2, y_2), (x_3, y_3), \dots,(x_n, y_n)) \]
where $x_i$ is a \textit{i\textsuperscript{th}} sample and $y_i$ is a desired model output after taking $x_i$ as an input. The goal of a supervised learning algorithm is to find such parameters of a model $f$  that will approximate the unknown underlying distribution $y_i = \hat{f}(x_i)$\cite{theoretical_ml}, or \textit{fit the training set}.

Supervised learning tasks can be divided further depending on the output values space:
\begin{itemize}
	\item If the set of valid outputs is finite, it's about the \textbf{classification} task ("yes/no" or category assignment)
	\item If the set of valid outputs is ordered and large enough to consider it infinite, or numeric, it's about the \textbf{regression} task (age, price estimation)
\end{itemize}
\textit{Ranking} (ordering an input data) and \textit{forecasting} (prediction of subsequent elements of a certain sequence) tasks also may be distinguished, albeit they heavily intersect with the previous two.

To define how good the model approximates the given data, the \textit{loss function} (or simply \textit{loss}) is being defined based on the difference between the model output and the ground truth. With a proper function choice, the learning task may be defined as a loss function optimization with respect to the model parameters. This allows to employ powerful numeric optimization algorithms.

The key difference between supervised learning and a straightforward numerical optimization is that optimization algorithm do care only about the model output over the training data, regardless the generalization. This may lead to the so-called \textit{overfitting} problem, when the model memorizes data instead of learning a pattern.

\section{Overfitting}

Low loss function value over the training data doesn't guarantee good performance over unseen samples. The plain example is a model memorizing a training data set and having a zero error on it, but yielding random output in response to the unknown input. This example graphically shows the difference between memorizing and generalizing.

Ergo, \textbf{overfitting} may be defined as a case when the model fits the training data well, but performs poorly on unseen data. To detect the overfitting, one needs to test a model over data not included into the training set. Thus, not all data are being fed into the model during training, but some part is being left untouched until it comes to the estimator performance evaluation. This piece of data is often referred as a \textbf{test set}.

Overfitting is a frequent situation when using powerful models, such as artificial neural nets. These models may represent a very large set of different functions including more complex than necessary to describe the distribution from which the training set was drawn. The problem is in relation with the Occam's Razor, and an overfitting occured implies violation the principle\cite{overfitting}.

To combat overfitting, variety of methods is being applied:
\begin{itemize}
	\item \textbf{Gathering more data.} More samples \textit{from the same distribution} means the that during training model will see more diverse and densely located data points and will be less prone to memorizing instead of pattern extraction. One should pay attention to the data quality when adding more data to the existing data set: low-quality and noisy data may \textit{decrease} the model performance.
	\item \textbf{Usage of a simpler model.} A simpler, less representative model is less likely to learn such complex patterns as noise usually is, and is more likely to comply with the Occam's Razor.
	\item \textbf{Regularization.} Regularization is a process of adding additional constraints to the model. This technique is densely related to the previous point---regularized model may represent lesser set of functions. Model weight norm is usually being penalized; artificial neural nets may be regularized by zeroing output of a random neuron during training. Further regularization techniques also exist.
	\item \textbf{Data augmentation.} Data augmentation is a technique of an artificial samples number increasing without collecting more data. This involves transforming a sample without changing its semantic. A typical example is an image mirroring and rotation: if the task is to classify a cat photo as "Cat", the mirrored or rotated image still will contain the cat on it and may be appended to the training set under the same label.
\end{itemize}

It's worth to mention that \textbf{underfitting} also may occur when the model:
\begin{itemize}
	\item Wasn't trained enough and needs more training iterations to fit the data
	\item \textit{Too weak} to fit the data
\end{itemize}

The second case may be illustrated by fitting the quadratic data with linear regression model. Model weakness usually appears as similar, unsatisfying and not improving performance on training and test data. The solution is straightforward: more complex model.

\section{Models and Hyperparameter Tuning}

Machine learning \textbf{model} is a parameterized function used to approximate and generalize the underlying data. This function may be represented by a mathematical function (linear regression), set of rules (decision trees) or more complex methematical structure (neural networks). The model itself may represent multiple specific functions depending on its parameters, and the training process is being run to automatically pick them.

But there are values responsible to the \textit{shape} of model, such as a polynom degree in polynomial regression, tree depth in decision trees or an entire neural network architecture. These values cannot be learned since they have to be defined before the model instantiation, and should be picked by a machine learning specialist. These values are called \textbf{hyperparameters} and the process of picking the right hyperparameter value is called \textit{tuning}.

Hyperparameter cannot be tuned on the same data the model performance is being estimated on. By picking the best hyperparameter after testing it on a certain data set one adapts the model to this specific piece of data, and the model performance on it will be biased towards the better result. Thus, one has to tune hyperparameter on a \textbf{validation} data set disjoint from training and test sets.

\section{Deep Learning}

\textbf{Deep learning} is a subset of machine learning relying on deep artificial neural networks application (ANN). Word "deep" refers to the large number of hidden layers of the neural networks being used.

Deep Learning is notably different from the rest of machine learning methods, primarily due to the unique ANN capabilities. The key differences are:
\begin{itemize}
	\item \textbf{Bulky feature engineering is eliminated.} Classic ML algorithms heavily rely on the initial process of constructing more representative features from the raw data. This approach is problem-specific and often requires an expertise in a related domain. One of the most important (if not the most one) of the ANN advantages is a capability to infer features by themselves, simplifying the data preparation and letting the ML specialist to approach a problem without a domain-specific expertise.
	\item \textbf{ANN architecture is not problem-specific.} Classic ML algorithm choice is mostly dependent on the task field. ANN architecture is dictated by the data amount and type instead.
	\item \textbf{ANNs often require huge amount of data.} State-of-art neural nets contain millions of parameters and tend to overfit very easily. This disadvantage may be partially compensated by \textbf{transfer learning} mentioned below.
	\item \textbf{ANN training requires a lot of computational power.} ANNs are based on multiple matrix multiplications, which are RAM-hungry and are best done by GPU. This disadvantage limits ANN combination with such time-consuming techniques as cross-validation and ensembling.
\end{itemize} 

\section{Convolutional Neural Networks}

ConvNet brief description, differences from their predcessors ANNs, training process, backprop

\section{Performance Improvement Techniques}

Refer to Ensembling, Cross-validation, BatchNorm, Dropout, Adam optimizer papers

\chapter{Related Work}

More detailed methodology description

\section{Deep Learning}

Deep Learning by Goodfellow et al.
Dropout by Siravastava
BatchNorm by Szegedy/Ioffe

\section{DenseNet}

DenseNet fancy picture

DenseNet architecture description, optional comparison with ResNet and Inceptionv3

\section{Mask R-CNN}

MRCNN fancy picture

MRCNN architecture description

\section{Training Improvement Techniques}

Transfer Learning papers
Spatial Dropout, Specialized Dropouts for DenseNet

Optional - Adam optimizer

\chapter{Analysis and Design}

Data numeric analysis, why regression instead of classification, data samples and model parameters counts relation

Preprocess - Detect - Evaluate pipeline definition

Different model arrangements

\chapter{Realisation}

Keras, Colab, VGG Image Annotator, hyperparameters used

\chapter{Experiments}

Tables, graphs, RA2 Challenge results

\setsecnumdepth{part}
\chapter{Conclusion}

Pros and cons, what could be done better, \dots

\bibliographystyle{iso690}
\bibliography{mybibliographyfile}

\setsecnumdepth{all}
\appendix

\chapter{Acronyms}

\begin{description}
	\item[ANN] Artificial Neural Network
	\item[CNN] Convolutional Neural Network
	\item[ML] Machine Learning
\end{description}


\chapter{Contents of enclosed CD}

%change appropriately

\begin{figure}
	\dirtree{%
		.1 readme.txt\DTcomment{the file with CD contents description}.
		.1 exe\DTcomment{the directory with executables}.
		.1 src\DTcomment{the directory of source codes}.
		.2 wbdcm\DTcomment{implementation sources}.
		.2 thesis\DTcomment{the directory of \LaTeX{} source codes of the thesis}.
		.1 text\DTcomment{the thesis text directory}.
		.2 thesis.pdf\DTcomment{the thesis text in PDF format}.
		.2 thesis.ps\DTcomment{the thesis text in PS format}.
	}
\end{figure}

\end{document}
