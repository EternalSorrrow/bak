{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of nn_playground.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EternalSorrrow/bak/blob/master/Copy_of_nn_playground.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhHrufioZp3M",
        "colab_type": "text"
      },
      "source": [
        " MNIST CNN - Simple CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4BoK5KMZr7g",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCgikYxuZx6j",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "(x_train, y_train), (x_test, y_test) = data\n",
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33_AnbicZ4Lh",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "plt.figure()\n",
        "plt.imshow(x_train[0], cmap = plt.cm.gray)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7bX_h3Hackz",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "x_train, x_test = x_train / 255, x_test / 255 # Normalize data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Xxegn8hdp5F",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "x_train = x_train.reshape((-1, 28, 28, 1)) # Reshape data since the Keras expects an array of 3d (not 2d) tensors on input\n",
        "x_test = x_test.reshape((-1, 28, 28, 1))\n",
        "\n",
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGM_DdJQBRwC",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "import numpy as np\n",
        "np.unique(y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hthSqbtSdBDl",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "cat_num = 10\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, cat_num)\n",
        "y_test = keras.utils.to_categorical(y_test, cat_num) # Encode integer-expressed classes as a binary vectors\n",
        "\n",
        "print(y_train.shape, y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aA9EKJGTDgdu",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "print(y_train[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOmF7SwuarcR",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3,3), activation='relu', input_shape=(28,28, 1)))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Dropout(0.25)) # !!! Doesn't work without dropout here\n",
        "\n",
        "model.add(Flatten()) # ??? Why should we flatten the feature vector?\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUV2BsXdcNQJ",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='sgd',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Io9euVCqB3eW",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "batch_size = 128\n",
        "epochs = 25\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bS9Jv7pdKmF",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "eval_ = model.evaluate(x_test, y_test, verbose=0) # Score the model\n",
        "print('Test loss:', eval_[0])\n",
        "print('Test accuracy:', eval_[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QR4FKwWOJs03",
        "colab_type": "text"
      },
      "source": [
        "Test loss: 0.05813348390585916\n",
        "Test accuracy: 0.985\n",
        "\n",
        "Nice!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYEbB6SOHO3G",
        "colab_type": "text"
      },
      "source": [
        "More complex example: CIFAR-10 CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4jtAybdHsxC",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = cifar10.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KyJZ_g7Hxlc",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "(x_train, y_train), (x_test, y_test) = data\n",
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkSjoV_LH8WR",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "print(x_train[0][0,0,:])\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(x_train[0], cmap = plt.cm.gray)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czKQPhC6IAgd",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "x_train, x_test = x_train / 255, x_test / 255 # Normalize data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYKIO4JoISdk",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "print(x_train[0][0,0,:])\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(x_train[0], cmap = plt.cm.gray)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qszcp3hFITiz",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "import numpy as np\n",
        "np.unique(y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyTQVpkBIeov",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "cat_num = 10\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, cat_num)\n",
        "y_test = keras.utils.to_categorical(y_test, cat_num) # Encode integer-expressed classes as a binary vectors\n",
        "\n",
        "print(y_train.shape, y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-DdqPdeIkbH",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "#Copy-pasted previous model with the changed input_shape to (32, 23, 3)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3,3), activation='relu', input_shape=(32,32, 3)))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PVDlPDRI4vz",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='sgd',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezTjXhQ7I9Nh",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "batch_size = 128\n",
        "epochs = 100\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dp0-4T_LJBS9",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "eval_ = model.evaluate(x_test, y_test, verbose=0) # Score the model\n",
        "print('Test loss:', eval_[0])\n",
        "print('Test accuracy:', eval_[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E40jgvP5Ksbk",
        "colab_type": "text"
      },
      "source": [
        "Test loss: 0.9657731695175171\n",
        "Test accuracy: 0.6775\n",
        "\n",
        "Shouldn't expect more from the such primitive model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WgHv8wVKxKN",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3,3), activation='relu', input_shape=(32,32, 3)))\n",
        "model.add(Conv2D(32, (3,3), activation='relu')) # New convolution layer\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Dropout(0.15)) #Dropout 0.25 -> 0.15\n",
        "\n",
        "model.add(Conv2D(64, (3,3), activation='relu', input_shape=(32,32, 3)))\n",
        "model.add(Conv2D(64, (3,3), activation='relu')) \n",
        "model.add(MaxPooling2D(pool_size=(2,2))) # Additional Conv-Conv-MaxPool pattern with 64 filters\n",
        "\n",
        "model.add(Dropout(0.15))  #One more dropout layer\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(512, activation='relu')) #128 -> 512 neurons\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jj5-QBsVLYZj",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='sgd',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oz842R-XLdgx",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "batch_size = 128\n",
        "epochs = 100\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3j5_B3PcLfRw",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "eval_ = model.evaluate(x_test, y_test, verbose=0) # Score the model\n",
        "print('Test loss:', eval_[0])\n",
        "print('Test accuracy:', eval_[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkEtGXisPnQE",
        "colab_type": "text"
      },
      "source": [
        "Test loss: 1.0367052768707274\n",
        "Test accuracy: 0.7355\n",
        "\n",
        "There's still work to do..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21xrlGdwPyXF",
        "colab_type": "text"
      },
      "source": [
        "Some notices:\n",
        "- Dropouts have a drastic impact on models's performance. Introduced models didn't work completely without them.\n",
        "- Straightforward layer adding doesn't yield better result itself, with an any added layer hyperparameter tuning to realize deeper model's potential becomes substantially more tedious. Sometimes it's much easier to build simpler model rather than tune more complex."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fi7yMkq1XpoD",
        "colab_type": "text"
      },
      "source": [
        "MURA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSLYYhe0PqvO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Da8sx1sOPIN4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!rm -r 'drive/My Drive/MURA-v1.1'\n",
        "#!unzip -q 'drive/My Drive/MURA-v1.1.zip' -d 'drive/My Drive/'\n",
        "!ls 'drive/My Drive/MURA-v1.1'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOgy5TU9Xn_u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls 'drive/My Drive/MURA-v1.1/' ; echo '' ; head -5 'drive/My Drive/MURA-v1.1/train_image_paths.csv' ; echo ''\n",
        "!head -5 'drive/My Drive/MURA-v1.1/train_labeled_studies.csv'; echo '' ; head -5 'drive/My Drive/MURA-v1.1/valid_image_paths.csv'\n",
        "!echo '' ; head -240 'drive/My Drive/MURA-v1.1/valid_labeled_studies.csv' | tail -6\n",
        "!find . -name \\*.png | wc -l\n",
        "!cat  'drive/My Drive/MURA-v1.1/train_image_paths.csv' | wc -l\n",
        "!cat  'drive/My Drive/MURA-v1.1/valid_image_paths.csv' | wc -l"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKxCPRb3XxPU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "\n",
        "img = cv2.imread('drive/My Drive/MURA-v1.1/train/XR_SHOULDER/patient00001/study1_positive/image1.png')\n",
        "img.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqdWOgvaZBvF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(img, cmap = plt.cm.gray)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ol4Zy7ZDZZY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "#Sum of the cross-differences between all 3 pairs of channels to determine, can we use a grayscale image without substantional information loss\n",
        "diff_map = np.abs(img[:,:,0]-img[:, :, 1])+np.abs(img[:,:,0]-img[:, :, 2]) + np.abs(img[:,:,1]-img[:,:,2])\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(diff_map, cmap = plt.cm.gray)\n",
        "\n",
        "print(np.mean(diff_map), np.var(diff_map))#All 3 channels are the same, we can reduce the input tensor size 3x by using the grayscale image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yN69AlokaLD7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "paths = None\n",
        "\n",
        "image_size = (100, 100)\n",
        "use_single_channel = True\n",
        "interpolation = cv2.INTER_AREA\n",
        "\n",
        "with open('drive/My Drive/MURA-v1.1/train_image_paths.csv', 'r') as file:\n",
        "  paths = file.read().split('\\n')\n",
        "\n",
        "train_images = []\n",
        "for i, path in enumerate(paths):\n",
        "  img = cv2.imread('drive/My Drive/' + path)\n",
        "  if img is None:\n",
        "    print('None image on path:', path)\n",
        "  else:\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    img = cv2.resize(img, dsize=image_size, interpolation=interpolation)\n",
        "    path = \"\".join(path.replace('MURA-v1.1/train/', '').split('/')[:-1])\n",
        "    train_images.append((path, img))\n",
        "  if i % 1000 == 0:\n",
        "    print(i)\n",
        "\n",
        "\n",
        "print(train_images[0][0])\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.imshow(train_images[0][1], cmap = plt.cm.gray)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcE5eN9CK874",
        "colab_type": "text"
      },
      "source": [
        "It's supposed that the 100 x 100 x 1 image still contains enough information to recognise possible traumas/diseases\n",
        "\n",
        "Total input tensor size reduction is something like ~5 x 5 x 3 = 75 times"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aeab4xJH5Mw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "paths = None\n",
        "\n",
        "image_size = (100, 100)\n",
        "use_single_channel = True\n",
        "interpolation = cv2.INTER_AREA\n",
        "\n",
        "with open('drive/My Drive/MURA-v1.1/valid_image_paths.csv', 'r') as file:\n",
        "  paths = file.read().split('\\n')\n",
        "\n",
        "valid_images = []\n",
        "for i, path in enumerate(paths):\n",
        "  img = cv2.imread('drive/My Drive/' + path)\n",
        "  if img is None:\n",
        "    print('None image on path:', path)\n",
        "  else:\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    img = cv2.resize(img, dsize=image_size, interpolation=interpolation)\n",
        "    path = \"\".join(path.replace('MURA-v1.1/valid/', '').split('/')[:-1])\n",
        "    valid_images.append((path, img))\n",
        "  if i % 1000 == 0:\n",
        "    print(i)\n",
        "\n",
        "print(valid_images[0][0])\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.imshow(valid_images[0][1], cmap = plt.cm.gray)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yo11CzPa87rw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('drive/My Drive/MURA-v1.1/train_labeled_studies.csv', 'r') as file:\n",
        "  paths = file.read().split('\\n')\n",
        "\n",
        "if paths[-1] == '':\n",
        "  paths.pop()\n",
        "\n",
        "train_label_paths, train_labels = list(map(lambda x: \"\".join(x.replace('MURA-v1.1/train/', '').split('/')[:-1]), paths)), np.array(list(map(lambda x: x.split(',')[1], paths)))\n",
        "\n",
        "train_labels = dict(zip(train_label_paths, train_labels))\n",
        "for item in train_labels.items():\n",
        "  print(item)\n",
        "  break\n",
        "\n",
        "with open('drive/My Drive/MURA-v1.1/valid_labeled_studies.csv', 'r') as file:\n",
        "  paths = file.read().split('\\n')\n",
        "\n",
        "if paths[-1] == '':\n",
        "  paths.pop()\n",
        "\n",
        "valid_label_paths, valid_labels = list(map(lambda x: \"\".join(x.replace('MURA-v1.1/valid/', '').split('/')[:-1]), paths)), np.array(list(map(lambda x: x.split(',')[1], paths)))\n",
        "valid_labels = dict(zip(valid_label_paths, valid_labels))\n",
        "for item in valid_labels.items():\n",
        "  print(item)\n",
        "  break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nk0A4LBp_sC7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels_array = []\n",
        "for path, _ in train_images:\n",
        "  train_labels_array.append(train_labels[path])\n",
        "\n",
        "valid_labels_array = []\n",
        "for path, _ in valid_images:\n",
        "  valid_labels_array.append(valid_labels[path])\n",
        "\n",
        "print(len(train_images), len(train_labels_array))\n",
        "print(len(valid_images), len(valid_labels_array))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvmDHzilFxKB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "\n",
        "t_images = list(map(lambda x: x[1], train_images))\n",
        "v_images = list(map(lambda x: x[1], valid_images))\n",
        "\n",
        "t_labels = keras.utils.to_categorical(train_labels_array, 2)\n",
        "v_labels = keras.utils.to_categorical(valid_labels_array, 2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ct3edcxPJGpy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(t_images[0].shape, v_images[0].shape, t_labels[0], v_labels[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCc2BI7DISe_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t_images = np.array(t_images)\n",
        "v_images = np.array(v_images)\n",
        "\n",
        "print(t_images.shape, v_images.shape)\n",
        "\n",
        "t_images = t_images.astype(np.float32) * 1./255\n",
        "v_images = v_images.astype(np.float32) * 1./255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrKRBKW9JMIK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(t_images[0].shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qn8f8m_GUM1g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t_images = t_images.reshape((-1, 100, 100, 1))\n",
        "v_images = v_images.reshape((-1, 100, 100, 1))\n",
        "\n",
        "print(t_images.shape, v_images.shape, t_labels.shape, v_labels.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFGps-KCTC4Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import h5py\n",
        "\n",
        "#with h5py.File('mura_processed.h5', 'w') as hf:\n",
        "#    hf.create_dataset(\"train_images\",  data=t_images)\n",
        "#    hf.create_dataset(\"valid_images\",  data=v_images)\n",
        "#    hf.create_dataset(\"train_labels\",  data=t_labels)\n",
        "#    hf.create_dataset(\"valid_labels\",  data=v_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWAacVEtUYo2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import h5py\n",
        "\n",
        "#t_labels, t_images, v_labels, v_images = None, None, None, None\n",
        "\n",
        "#with h5py.File('mura_processed.h5', 'r') as hf:\n",
        "#    t_images = hf['train_images'][:]\n",
        "#    t_labels = hf['train_labels'][:]\n",
        "#    v_images = hf['valid_images'][:]\n",
        "#    v_labels = hf['valid_labels'][:]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPnv9AaZGceb",
        "colab_type": "text"
      },
      "source": [
        "MURA Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdWJnDrjGFE5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(64, (3,3), activation='relu', input_shape=(100, 100, 1)))\n",
        "model.add(Conv2D(64, (3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(128, (3,3), activation='relu'))\n",
        "model.add(Conv2D(128, (3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(256, (3,3), activation='relu'))\n",
        "model.add(Conv2D(256, (3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(512, (3,3), activation='relu'))\n",
        "model.add(Conv2D(512, (3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(4096, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(4096, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPihXSDmXRz3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=False,\n",
        "    featurewise_std_normalization=False,\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=False,\n",
        "    fill_mode='nearest')\n",
        "\n",
        "datagen.fit(t_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCfiiLTPIC6u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Once we've instantiated our model, we'd need a callback, backing it up\n",
        "#every n epochs to prevent progression loss once something goes wrong\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"best_model.hdf5\", monitor='loss', verbose=1,\n",
        "    save_best_only=True, mode='auto', period=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPbrw7tDIKlx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 256\n",
        "epochs = 50\n",
        "\n",
        "model.fit_generator(datagen.flow(t_images, t_labels, batch_size=batch_size), validation_data=(v_images, v_labels), epochs=epochs, callbacks = [checkpoint])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pXWjArVjovK",
        "colab_type": "text"
      },
      "source": [
        "Notes\n",
        "\n",
        "Questions:\n",
        "\n",
        "- Why should I use softmax as a last layer output? Where else the Softmax could be useful? -> Simonsays video\n",
        "- What is neuron saturation? How does this relate with using the sigmoid functions?\n",
        "- Why should I use sigmoids as an output functions?\n",
        "- Gradient vanishing/explosion and it's relation with an activation function type\n",
        "- How does the dropout layers increase the ANN learning performance? -> Geoffrey Hinton, drawback: longer learning\n",
        "- What an ANN-building heuristics are exist?\n",
        "- What are the details of an ANN overfitting?\n",
        "- How does the convolutional layers learn?\n",
        "- What is ANN regularization, what problemes does it solve and it's relations with performance.\n",
        "- What are the factors influencing an ANN performance? Where an attention should be given while trying to implement an ANN to increase it's learning and decisioning speed?\n",
        "- Kernel striding, its pros and cons\n",
        "- Capsule Network -> Geoffrey Hinton\n",
        "- Network in Network\n",
        "- Transfer Learning\n",
        "- SGD hyperparameters\n",
        "- Delta Rule\n",
        "- Novikoff theorem\n",
        "- NN: the beginning\n",
        "\n",
        "AlexNet\n",
        "- Sparse connections due to the dual-GPU realization\n",
        "- Local Response Normalization\n",
        "- Overlapping Pooling\n",
        "- Extracting 5 image patches and averaging the predictions for all of them to produce the final evaluation\n",
        "- Applying the PCA on the image intensities and adding multiples of a principal components\n",
        "- Dividing learning rate by 10 when validation error stopped reducing with the current value with the initial value of 0.01\n",
        "- Occurring kernel specialization while training on different GPU's\n",
        "- Dropouts on the first two fully-connected layers\n",
        "\n",
        "Deconvolutional Network\n",
        "- Deconv net is a way to visualize a feature map, produced by one of the layers of the CNN\n",
        "- Maps feature map produced by filter to the original image's color space, showing patterns that excited the layer\n",
        "- Conventional CNN records the maxima (\"switches\") positions before the pooling application\n",
        "- A layer output is then being sended to the DeconvNN, which de-pools the image using switches by placing the input map pixels into switch positions, rectifies them by ReLU and uses transposed filters to reconstruct the input image\n",
        "- Can be used to \"debug\" CNN by visualizing the feature maps and filters, giving a knowledge about artifacts and \"dead\" filters\n",
        "\n",
        "NN work study:\n",
        "- A learned net has a hierarchical convolutional layer inference - lower layers are responsible for the lower-level features, such as edges (L1 in the paper), corners (L2), textures/patterns or text (L3), human silhouettes and animal body parts (L4). L5 mostly shows complete objects in different pose variations - higher levels in common are more and more class-specific and are targeting to detect more complex and large-scale features\n",
        "- Lower layers converge in a few epochs, while higher-level layers require considerable more time to learn\n",
        "- Lower layers output is very sensitive to rotation/translation/scaling, while higher layers output is much more robust in relation to the last two transformations, resulting in linear value change. CNN's are generally not invariant to the image rotation, except the radial symmetry cases.\n",
        "- CNNs poorly detect occluded objects\n",
        "\n",
        "ZF Net\n",
        "- The used CNN had a similar to the AlexNet structure, except being tightly-connected and using 7 x 7 filters with stride 2 vs 11 x 11 stride 4 filters to keep more local information\n",
        "- Removing 2 fully-connected or 2 convolutional layers decreased the model precision for a bit, while removing 2 conv and 2 FF layers decreased the precision dramatically. Conclusion: overall depth is important.\n",
        "- Trained on the one dataset CNN can work as a feature extractor for using on any another dataset by removing the last layer and putting the suitable classifier instead.\n",
        "\n",
        "VGG Net\n",
        "- Using only 3 x 3 filters arranged into more layers - that yields more discriminative model with the lower parameters count\n",
        "- The intuition is that two 3 x 3 filters have the same recepting filed as a one 5 x 5, and three 3 x 3 as a one 7 x 7. And, three 3 x 3 x C filters contain 3 x (3 x 3 x C) = 27C parameters, in comparison to the one 7 x 7 x C = 49C parameter filter, with the included non-linearity.\n",
        "- Using of the 1 x 1 x C filters projecting image to the same space, but through the composition of a few ReLU's and with no effect on the receptive field\n",
        "- Doubled batch size, weight decay regularization\n",
        "- Complex initialization: training less complex structure and using it's last N layers as the first three of the more complex model with the high learning rate to let them change\n",
        "- The're exist another random initialization techniques that render the metod above obsolete (Glorot & Bengio 2010)\n",
        "- Multi-scale approaches - the first one is using of 2 image scales - with shortest sides of an image as 256 and 384. Learning on 384 px image was speeded up by training on 256 px images and using pre-trained net to learn on 384 with initially low learning rate (0.001)\n",
        "- The second multi-scale approach is rescaling the image isotropically to make it's shortest side equal to random number between [Smin, Smax]. Smin was chosen as 256, and Smax as 512. Learning was speeded up by initializing with weights of the pre-trained model on 384 px images.\n",
        "\n",
        "DenseNet:\n",
        "- Every layer is connected to every other layer - every layer uses maps from all previous layers as inputs and it's output maps are used in all next layers.\n",
        "- Dense topology alleviates the vanishing-gradient problem, strengthens feature propagation, encourages feature reuse, substantially reduces the number of parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4g1bLOshAZrr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}